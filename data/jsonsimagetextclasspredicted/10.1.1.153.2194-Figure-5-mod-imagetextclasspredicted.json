{"CaptionBB": [68, 438, 398, 528], "Width": 850, "Mention": ["The Labeled Faces in the Wild (LFW) [19] data set consists\nof 13,233 images of 5,749 people, which are organized into\n2 views \u2013 a development set of 2,200 pairs for training and\n1,000 pairs for testing, on which to build models and choose\nfeatures; and a 10-fold cross-validation set of 6,000 pairs,\non which to evaluate final performance. We use View 1\nfor high-level model selection and evaluate our performance\non each of the folds in View 2 using the \u201cimage restricted\nconfiguration,\u201d as follows.\nFor each split, we train a final classifierD on the training\ndata and evaluate on the test data. Receiver Operating Char-\nacteristic (ROC) curves are obtained by saving the classifier\noutputs for each test pair and then sliding a threshold over\nall values to obtain different false positive/detection rates.\nAn overall accuracy is obtained by using only the signs of\nthe outputs and counting the number of errors in classifica-\ntion. The standard deviation for the accuracy is obtained by\nlooking at the accuracies for each fold individually.\nFigure 5 shows results on LFW for our attribute clas-\nsifiers (red line), simile classifiers (blue line), and a hy-\nbrid of the two (green line), along with several previous\nmethods (dotted lines). The accuracies for each method are\n83.62%\u00b1 1.58%, 84.14%\u00b1 1.31%, and 85.29%\u00b1 1.23%,\n"], "ImageBB": [67, 102, 404, 433], "ImageText": [], "Number": 5, "GoldLabelsTagged": true, "Height": 1100, "Caption": "Figure 5: Face Verification Results on LFW: Performance of our attribute classifiers, simile classifiers, and a hybrid of the two are shown in solid red, blue, and green, respectively. All 3 of our methods outperform all previous methods (dashed lines). Our highest accuracy is 85.29%, which corresponds to a 31.68% lower error rate than the previous state-of-the-art. ", "SomethingWrong": true, "Type": "Figure", "Page": 6, "DPI": 100}